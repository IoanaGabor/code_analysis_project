{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdhGW1MxQjnz",
        "outputId": "872ea925-768f-49fe-9cc5-fb9877d7f755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (1.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install polars\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "# Define the paths for the dataset\n",
        "splits = {\n",
        "    'train': 'hf://datasets/blastwind/deprecated-github-code-haskell-function/data/train-*-of-*.parquet',\n",
        "    'test': 'hf://datasets/blastwind/deprecated-github-code-haskell-function/data/test-*-of-*.parquet',\n",
        "    'valid': 'hf://datasets/blastwind/deprecated-github-code-haskell-function/data/valid-00000-of-00001-636cb804972d8982.parquet'\n",
        "}\n",
        "\n",
        "# Load the training split using Polars\n",
        "df = pl.read_parquet(splits['train'])\n",
        "\n"
      ],
      "metadata": {
        "id": "3WsHzUqBVvnd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the rows where \"is_commented\" is True\n",
        "true_count = df.filter(pl.col(\"is_commented\") == True).filter(pl.col(\"is_signatured\") == True).height\n",
        "\n",
        "print(f\"Number of rows with 'is_commented' set to True: {true_count}\")\n",
        "\n",
        "dataframe = df.to_pandas()\n",
        "\n",
        "dataframe = dataframe.loc[\n",
        "    (dataframe[\"is_commented\"] == True) & (dataframe[\"n_ast_nodes\"] < 50),\n",
        "    [\"full_code\", \"uncommented_code\", \"function_only_code\"]\n",
        "]\n",
        "\n",
        "\n",
        "dataframe[\"comments\"] = dataframe.apply(\n",
        "    lambda row: row[\"full_code\"].replace(row[\"uncommented_code\"], \"\").strip(), axis=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I14IsBN4ep0Z",
        "outputId": "ee1a15c1-88d5-49c0-c351-c3e80f1cd64d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with 'is_commented' set to True: 473397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98_gRPuEhzTI",
        "outputId": "8c4261da-42db-4763-ba4d-9fee6d4f0a09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "954616"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tree_sitter\n",
        "!pip install tree_sitter_haskell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5QUCsAKihb-",
        "outputId": "80de09d4-3dd8-48db-833a-2b2f4593289d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tree_sitter in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: tree_sitter_haskell in /usr/local/lib/python3.10/dist-packages (0.23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tree_sitter_haskell as tshaskell\n",
        "import numpy as np\n",
        "from tree_sitter import Language, Parser\n",
        "\n",
        "\n",
        "HS_LANGUAGE = Language(tshaskell.language())\n",
        "parser = Parser(HS_LANGUAGE)\n"
      ],
      "metadata": {
        "id": "XNf9tk_JjQRH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tree_features(code):\n",
        "    try:\n",
        "        example_bytes = code.encode()\n",
        "        tree = parser.parse(example_bytes)\n",
        "        root_node = tree.root_node\n",
        "\n",
        "        def extract_features(node, parent_index=None, nodes=[], edges=[]):\n",
        "            node_type = node.type\n",
        "            start_pos = node.start_point\n",
        "            end_pos = node.end_point\n",
        "            code_value = code[node.start_byte:node.end_byte]\n",
        "            feature_vector = [node_type, code_value, start_pos[0], start_pos[1], end_pos[0], end_pos[1]]\n",
        "            node_index = len(nodes)\n",
        "            nodes.append(feature_vector)\n",
        "\n",
        "            if parent_index is not None:\n",
        "                edges.append((parent_index, node_index))\n",
        "\n",
        "            for child in node.children:\n",
        "                extract_features(child, parent_index=node_index, nodes=nodes, edges=edges)\n",
        "\n",
        "            return nodes, edges\n",
        "\n",
        "        nodes, edge_list = extract_features(root_node)\n",
        "\n",
        "        num_nodes = len(nodes)\n",
        "        adj_matrix = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
        "        for parent, child in edge_list:\n",
        "            adj_matrix[parent, child] = 1\n",
        "\n",
        "        return nodes, adj_matrix\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing code: {e}\")\n",
        "        return None, None\n",
        "dataframe[\"nodes\"], dataframe[\"adjacency_matrix\"] = zip(*dataframe[\"function_only_code\"].apply(extract_tree_features))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g9xsJdoSjmAA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe[\"nodes\"].size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAQoO4GqcsO",
        "outputId": "d0c4e39d-f6b5-4c09-abca-7cd03804f697"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXGNXmBEtjy_",
        "outputId": "db41449a-dfe9-4c00-8059-2066492eb822"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Layer\n",
        "from keras import activations\n",
        "import keras.backend as K\n",
        "\n",
        "class GCNLayer(Layer):\n",
        "    def __init__(self, units, activation='relu', initializer='glorot_uniform', sparse=False, use_bias=True, **kwargs):\n",
        "        self.activation = activations.get(activation)\n",
        "        self.output_dim = units\n",
        "        self.initializer = initializer\n",
        "        self.sparse = sparse\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        super(GCNLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                          shape=(input_shape[0][-1], self.output_dim),\n",
        "                                          initializer=self.initializer,\n",
        "                                          trainable=True)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name='bias',\n",
        "                                              shape=(self.output_dim,),\n",
        "                                              initializer='zeros',\n",
        "                                              trainable=True)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        super(GCNLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        assert isinstance(x, list)\n",
        "        # # Get shapes of our inputs and weights\n",
        "        nodes, edges = x\n",
        "        edges += K.eye(int(edges.shape[1]))\n",
        "        output = tf.matmul(edges,nodes)\n",
        "        output = tf.matmul(output, self.kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output += self.bias\n",
        "\n",
        "        return self.activation(output)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        return (None,input_shape[0][1], self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'units': self.output_dim,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "        }\n",
        "\n",
        "        base_config = super(GCNLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "metadata": {
        "id": "qImh_MqWthex"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras.layers import Input, Dense, Embedding, Activation, concatenate, Flatten, GRU, TimeDistributed, dot\n",
        "from keras.models import Model\n",
        "\n",
        "class CodeGNNGRU:\n",
        "    def __init__(self, config):\n",
        "        config['modeltype'] = 'codegnngru'\n",
        "\n",
        "        self.config = config\n",
        "        self.tdatvocabsize = config['tdatvocabsize']\n",
        "        self.comvocabsize = config['comvocabsize']\n",
        "        self.smlvocabsize = config['smlvocabsize']\n",
        "        self.tdatlen = config['tdatlen']\n",
        "        self.comlen = config['comlen']\n",
        "        self.smllen = config['maxastnodes']\n",
        "\n",
        "        self.config['batch_maker'] = 'graph_multi_1'\n",
        "\n",
        "        self.embdims = 100\n",
        "        self.smldims = 256\n",
        "        self.recdims = 256\n",
        "        self.tdddims = 256\n",
        "\n",
        "    def create_model(self):\n",
        "\n",
        "        tdat_input = Input(shape=(self.tdatlen,))\n",
        "        com_input = Input(shape=(self.comlen,))\n",
        "        node_input = Input(shape=(self.smllen,))\n",
        "        edge_input = Input(shape=(self.smllen, self.smllen))\n",
        "\n",
        "        tdel = Embedding(output_dim=self.embdims, input_dim=self.tdatvocabsize, mask_zero=False)\n",
        "        tde = tdel(tdat_input)\n",
        "\n",
        "        se = tdel(node_input)\n",
        "\n",
        "        tenc = GRU(self.recdims, return_state=True, return_sequences=True)\n",
        "        tencout, tstate_h = tenc(tde)\n",
        "\n",
        "        de = Embedding(output_dim=self.embdims, input_dim=self.comvocabsize, mask_zero=False)(com_input)\n",
        "        dec = GRU(self.recdims, return_sequences=True)\n",
        "        decout = dec(de, initial_state=tstate_h)\n",
        "\n",
        "        tattn = dot([decout, tencout], axes=[2, 2])\n",
        "        tattn = Activation('softmax')(tattn)\n",
        "        tcontext = dot([tattn, tencout], axes=[2, 1])\n",
        "\n",
        "        astwork = se\n",
        "\n",
        "        # provide a graph layer for each number of hops 1->2->3->N\n",
        "        for i in range(self.config['asthops']):\n",
        "            astwork = GCNLayer(100)([astwork, edge_input])\n",
        "\n",
        "        astwork = GRU(self.recdims, return_sequences=True)(astwork, initial_state=tstate_h)\n",
        "\n",
        "        # attend decoder words to nodes in ast\n",
        "        aattn = dot([decout, astwork], axes=[2, 2])\n",
        "        aattn = Activation('softmax')(aattn)\n",
        "        acontext = dot([aattn, astwork], axes=[2, 1])\n",
        "\n",
        "        context = concatenate([tcontext, decout, acontext])\n",
        "\n",
        "        out = TimeDistributed(Dense(self.tdddims, activation=\"relu\"))(context)\n",
        "\n",
        "        out = Flatten()(out)\n",
        "        out1 = Dense(self.comvocabsize, activation=\"softmax\")(out)\n",
        "\n",
        "        model = Model(inputs=[tdat_input, com_input, node_input, edge_input], outputs=out1)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
        "        return self.config, model\n"
      ],
      "metadata": {
        "id": "BWrWF8f6txTV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Example configuration dictionary\n",
        "config = {\n",
        "    'tdatvocabsize': 5000,\n",
        "    'comvocabsize': 5000,\n",
        "    'smlvocabsize': 5000,\n",
        "    'tdatlen': 100,\n",
        "    'comlen': 50,\n",
        "    'maxastnodes': 70,\n",
        "    'asthops': 3,\n",
        "}\n",
        "\n",
        "# Create the model\n",
        "model_instance = CodeGNNGRU(config)\n",
        "config, model = model_instance.create_model()\n",
        "\n",
        "# Prepare inputs for the model\n",
        "tdat_input = np.random.randint(0, config['tdatvocabsize'], (len(dataframe), config['tdatlen']))\n",
        "com_input = np.random.randint(0, config['comvocabsize'], (len(dataframe), config['comlen']))\n",
        "\n",
        "# Normalize nodes and adjacency matrices to fit input shapes\n",
        "node_input = np.zeros((len(dataframe), config['maxastnodes']), dtype=np.float32)\n",
        "edge_input = np.zeros((len(dataframe), config['maxastnodes'], config['maxastnodes']), dtype=np.float32)\n",
        "\n",
        "for i, (nodes, adj_matrix) in enumerate(zip(dataframe[\"nodes\"], dataframe[\"adjacency_matrix\"])):\n",
        "    num_nodes = min(len(nodes), config['maxastnodes'])\n",
        "    node_feature_dim = 4\n",
        "    node_input = np.zeros((len(dataframe), config['maxastnodes'], node_feature_dim), dtype=np.float32)\n",
        "    edge_input[i, :num_nodes, :num_nodes] = adj_matrix[:num_nodes, :num_nodes]\n",
        "\n",
        "# Create target output (dummy example)\n",
        "target_output = to_categorical(np.random.randint(0, config['comvocabsize'], len(dataframe)))\n",
        "\n",
        "# Fit the model\n",
        "model.fit(\n",
        "    [tdat_input, com_input, node_input, edge_input],\n",
        "    target_output,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        ")\n"
      ],
      "metadata": {
        "id": "dGMm76R9uLfQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}